import gradio as gr
import tempfile
from google.cloud import firestore
from google.cloud.firestore_v1.base_vector_query import DistanceMeasure
from google.cloud.firestore_v1.vector import Vector
import vertexai
from vertexai.vision_models import Image, MultiModalEmbeddingModel
from vertexai import rag
from vertexai.generative_models import GenerativeModel, Tool

# Vertex AI & Firestore é…ç½®
PROJECT_ID = "a94-project-ai-specialization"
vertexai.init(project=PROJECT_ID, location="us-central1")
firestore_client = firestore.Client()
collection = firestore_client.collection("images-demo")

# åˆå§‹åŒ–æ¨¡å‹
model = MultiModalEmbeddingModel.from_pretrained("multimodalembedding@001")

# -------- æ–‡æœ¬RAGæ£€ç´¢ç›¸å…³ --------
corpus_name = "projects/a94-project-ai-specialization/locations/us-central1/ragCorpora/3379951520341557248"

def rag_gemini_tool_query(query_text: str):
    try:
        rag_retrieval_tool = Tool.from_retrieval(
            retrieval=rag.Retrieval(
                source=rag.VertexRagStore(
                    rag_resources=[
                        rag.RagResource(
                            rag_corpus=corpus_name,
                        )
                    ],
                    rag_retrieval_config=rag.RagRetrievalConfig(
                        top_k=5,
                        filter=rag.utils.resources.Filter(vector_distance_threshold=0.5),
                    ),
                ),
            )
        )
        rag_model = GenerativeModel(
            model_name="gemini-2.0-flash-001", tools=[rag_retrieval_tool]
        )
        response = rag_model.generate_content(query_text)
        return response.text
    except Exception as e:
        return f"æŸ¥è¯¢å‡ºé”™: {str(e)}"

def query_rag(query_text):
    if not query_text.strip():
        return "è¯·è¾“å…¥æŸ¥è¯¢å†…å®¹"
    result = rag_gemini_tool_query(query_text)
    return result

# -------- å›¾ç‰‡å‘é‡æ£€ç´¢ç›¸å…³ --------
def get_image_embedding_local(image_path, dimension=512):
    image = Image.load_from_file(image_path)
    embeddings = model.get_embeddings(
        image=image,
        contextual_text="",  # å¯æ ¹æ®éœ€è¦å¡«å†™
        dimension=dimension,
    )
    return list(embeddings.image_embedding)

def find_similar_images(embedding_vector, top_k=5):
    vector_query = collection.find_nearest(
        vector_field="embedding_field",
        query_vector=Vector(embedding_vector),
        distance_measure=DistanceMeasure.EUCLIDEAN,
        limit=top_k,
    )
    urls = []
    for doc in vector_query.stream():
        doc_id = doc.get("id")
        docs = collection.where("id", "==", doc_id).limit(1).stream()
        for d in docs:
            data = d.to_dict()
            if "path" in data:
                urls.append(data["path"])
    return urls

def gradio_image_search(input_image, top_k):
    # ä¿å­˜ä¸Šä¼ å›¾ç‰‡åˆ°ä¸´æ—¶æ–‡ä»¶
    with tempfile.NamedTemporaryFile(suffix=".jpg", delete=False) as tmp:
        input_image.save(tmp.name)
        image_path = tmp.name

    # ç”Ÿæˆembedding
    embedding_vector = get_image_embedding_local(image_path)

    # æŸ¥è¯¢æœ€è¿‘é‚»å›¾ç‰‡
    urls = find_similar_images(embedding_vector, top_k=top_k)

    # è¿”å›å›¾ç‰‡URLåˆ—è¡¨ï¼Œgradioä¼šè‡ªåŠ¨å±•ç¤º
    return urls

# -------- Gradioå¤šæ ‡ç­¾é¡µUI --------
with gr.Blocks(title="RAG+å›¾ç‰‡å‘é‡æ£€ç´¢") as demo:
    gr.Markdown("# ğŸ” æ™ºèƒ½æ£€ç´¢ç³»ç»Ÿ\næ”¯æŒæ–‡æœ¬RAGæ™ºèƒ½é—®ç­”å’Œå›¾ç‰‡ç›¸ä¼¼æ£€ç´¢ã€‚")

    with gr.Tab("æ–‡æœ¬RAGæ™ºèƒ½æ£€ç´¢"):
        gr.Markdown("### ğŸ¤– æ–‡æœ¬RAGæ™ºèƒ½æ£€ç´¢\nè¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼Œç³»ç»Ÿå°†åŸºäºRAGæŠ€æœ¯ä¸ºæ‚¨æä¾›æ™ºèƒ½å›ç­”ã€‚")
        query_input = gr.Textbox(
            label="è¯·è¾“å…¥æ‚¨çš„æŸ¥è¯¢",
            placeholder="ä¾‹å¦‚ï¼šæˆ‘æƒ³è´­ä¹°Vishudhå“ç‰Œçš„äº§å“ï¼Œæœ‰ä»€ä¹ˆæ¨èä¸”ä»·æ ¼ä¾¿å®œçš„å—ï¼Ÿ",
            lines=4,
            max_lines=8,
            container=True,
            scale=1
        )
        query_button = gr.Button("ğŸ” å¼€å§‹æŸ¥è¯¢", variant="primary", size="lg", scale=1)
        result_output = gr.Textbox(
            label="æŸ¥è¯¢ç»“æœ",
            lines=10,
            max_lines=20,
            interactive=False,
            container=True,
            scale=1
        )
        query_button.click(
            fn=query_rag,
            inputs=query_input,
            outputs=result_output
        )
        query_input.submit(
            fn=query_rag,
            inputs=query_input,
            outputs=result_output
        )

    with gr.Tab("å›¾ç‰‡å‘é‡æ£€ç´¢"):
        gr.Markdown("### ğŸ–¼ï¸ å›¾ç‰‡å‘é‡æ£€ç´¢\nä¸Šä¼ ä¸€å¼ å›¾ç‰‡ï¼Œæ£€ç´¢å›¾åº“ä¸­æœ€ç›¸ä¼¼çš„å›¾ç‰‡ã€‚")
        with gr.Row():
            with gr.Column():
                input_image = gr.Image(type="pil", label="ä¸Šä¼ å›¾ç‰‡")
                topk_slider = gr.Slider(1, 10, value=5, step=1, label="TopK æœ€é‚»è¿‘æ•°é‡")
                search_btn = gr.Button("å¼€å§‹æ£€ç´¢")
            with gr.Column():
                gallery = gr.Gallery(label="ç›¸ä¼¼å›¾ç‰‡å±•ç¤º", show_label=True, columns=5, height="auto")

        search_btn.click(
            fn=gradio_image_search,
            inputs=[input_image, topk_slider],
            outputs=gallery
        )
        input_image.change(
            fn=gradio_image_search,
            inputs=[input_image, topk_slider],
            outputs=gallery
        )

if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=7860) 